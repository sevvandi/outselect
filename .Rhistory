preds[1,]
Ensemble_M_IQR_best[1,]
LOF_Min_Max_best[1,]
auc_diff <- matrix(0, nrow=nrow(out), ncol=8)
for(i in 1:dim(out)[1]){
methods_inds <- order(out[i,], decreasing = TRUE)
for(j in 1:8){
preds[i,j] <- sum(actual_best[i]%in% methods_inds[1:j])>0
Ensemble_M_IQR_best[i,j] <- sum(1 %in% methods_inds[1:j])>0
LOF_Min_Max_best[i,j] <- sum(2 %in% methods_inds[1:j])>0
KNN_Median_IQR_best[i,j] <- sum(3 %in% methods_inds[1:j])>0
FAST_ABOD_Min_Max_best[i,j] <- sum(4 %in% methods_inds[1:j])>0
iForest_Median_IQR_best[i,j] <- sum(5 %in% methods_inds[1:j])>0
KDEOS_Median_IQR_best[i,j] <- sum(6 %in% methods_inds[1:j])>0
KDEOS_Min_Max_best[i,j] <- sum(7 %in% methods_inds[1:j])>0
LDF_Min_Max_best[i,j] <- sum(8 %in% methods_inds[1:j])>0
# AUC gain
auc_diff[i,j] <- max(perf_vals_roc_subset[i, methods_inds[1:j]]) - perf_vals_roc_subset[i,3]
}
}
head(preds)
dim(preds)
apply(preds,2, mean)
predicted <- apply(preds,2, mean)
Ens <- apply(Ensemble_M_IQR_best, 2, mean)
Ens
LOF <- apply(LOF_Min_Max_best,2, mean)
LOF
KNN <- apply(KNN_Median_IQR_best,2, mean)
KNN
FAbod <- apply(FAST_ABOD_Min_Max_best,2,best)
FAbod <- apply(FAST_ABOD_Min_Max_best,2,mean)
FAbod
iFor <- apply(iForest_Median_IQR_best,2,mean)
iFor
KdeosQ <- apply(KDEOS_Median_IQR_best, 2, mean)
KdeosM <- apply(KDEOS_Min_Max_best, 2, mean)
LDFM <- apply(LDF_Min_Max_best, 2, mean)
LDFM
df <- cbind.data.frame(predicted, Ens, LOF, KNN, FAbod, iFor, KdeosQ, KdeosM, LDFM )
colnames(preds)
colnames(out)
colnames(df) <- c("Predicted", colnames(out))
dfm <- melt(df)
dfm <- reshape2::melt(df)
head(dfm)
df <- cbind.data.frame(1:8, predicted, Ens, LOF, KNN, FAbod, iFor, KdeosQ, KdeosM, LDFM )
colnames(df) <- c("Number", "Predicted", colnames(out))
head(df)
dfm <- reshape2::melt(df)
head(dfm)
dfm <- reshape2::melt(df, id="Number")
head(dfm <- reshape2::melt(df, id="Number")
)
head(dfm)
ggplot(dfm, aes(Number, value)) + geom_point(aes(color=variable))
library("ggplot2")
ggplot(dfm, aes(Number, value)) + geom_point(aes(color=variable))
ggplot(dfm, aes(Number, value)) + geom_line(aes(color=variable))
ggplot(dfm, aes(Number, value)) + geom_line(aes(color=variable)) + theme_bw()
FAbod
predicted
predicted <- apply(preds,2, mean)
Ens <- apply(Ensemble_M_IQR_best, 2, mean)
LOF <- apply(LOF_Min_Max_best,2, mean)
KNN <- apply(KNN_Median_IQR_best,2, mean)
FAbod <- apply(FAST_ABOD_Min_Max_best,2,mean)
iFor <- apply(iForest_Median_IQR_best,2,mean)
KdeosQ <- apply(KDEOS_Median_IQR_best, 2, mean)
KdeosM <- apply(KDEOS_Min_Max_best, 2, mean)
LDFM <- apply(LDF_Min_Max_best, 2, mean)
df <- cbind.data.frame(1:8, predicted, Ens, LOF, KNN, FAbod, iFor, KdeosQ, KdeosM, LDFM )
colnames(df) <- c("Number", "Predicted", colnames(out))
dfm <- reshape2::melt(df, id="Number")
ggplot(dfm, aes(Number, value)) + geom_line(aes(color=variable)) + theme_bw()
head(dfm)
colnames(df)
ggplot(dfm, aes(Number, value)) + geom_line(aes(color=variable)) + theme_bw()
iFor
predicted
iFor
FAbod
ggplot(dfm, aes(Number, value)) + geom_line(aes(color=variable),size=1) + theme_bw()
df <- cbind.data.frame(1:8, predicted, KNN )
colnames(df) <- c("Number", "Predicted", "KNN_Median_IQR")
dfm <- reshape2::melt(df, id="Number")
ggplot(dfm, aes(Number, value)) + geom_line(aes(color=variable),size=1) + theme_bw()
ggplot(dfm, aes(Number, value)) + geom_line(aes(color=variable),size=1)+ ylab("Percentage") + xlab("Number of methods") + theme_bw()
head(auc_diff)
dim(auc_diff)
colnames(auc_diff) <- c(1,2,3,4,5,6,7,8)
colnames(auc_diff)
auc_dff_mlt <- melt(auc_diff)
auc_dff_mlt <-reshape2::melt(auc_diff)
head(auc_dff_mlt)
ggplolt(auc_dff_mlt, aes(value)) + geom_boxplot(Var2)
ggplot(auc_dff_mlt, aes(value)) + geom_boxplot(Var2)
head(auc_diff)
auc_dff_mlt <-reshape2::melt(auc_diff)
head(auc_dff_mlt)
ggplot(auc_dff_mlt, aes(value)) + geom_boxplot(Var1)
ggplot(auc_dff_mlt, aes(value)) + geom_boxplot(aes(Var1))
ggplot(auc_dff_mlt, aes(value)) + geom_boxplot(aes(group=Var1))
ggplot(auc_dff_mlt, aes(Var1, value)) + geom_boxplot(aes(group=Var1))
ggplot(auc_dff_mlt, aes(Var1, value)) + geom_boxplot()
colnames(auc_diff) <- c("1M", "2M", "3M", "4M", "5M", "6M", "7M", "8M")
auc_dff_mlt <-reshape2::melt(auc_diff)
ggplot(auc_dff_mlt, aes(Var1, value)) + geom_boxplot()
head(auc_dff_mlt)
head(auc_diff)
ggplot(auc_dff_mlt, aes(Var2, value)) + geom_boxplot()
ggplot(auc_dff_mlt, aes(Var2, value)) + geom_boxplot() + xlab("Number of methods") + ylab("AUC difference")
auc_diff_summary <- apply(auc_diff,2,function(x) sum(x > 0) )
auc_diff_summary
auc_diff_summary <- apply(auc_diff,2,function(x) sum(x > 0) )/dim(auc_diff)[1]
auc_diff_summary
auc_diff_summary <- apply(auc_diff,2,function(x) sum(x >= 0) )/dim(auc_diff)[1]
auc_diff_summary
head(auc_diff)
auc_diff_summary <- apply(auc_diff,2,function(x) length(x >= 0) )/dim(auc_diff)[1]
auc_diff_summary
auc_diff_summary <- apply(auc_diff,2,function(x) sum(x >= 0) )/dim(auc_diff)[1]
auc_diff_summary
auc_diff_summary2 <- apply(auc_diff,2,function(x) sum(x > 0) )/dim(auc_diff)[1]
auc_diff_summary2
sum(pred_perf_diff1 >=0)/length(pred_perf_diff3)
length(pred_perf_diff3)
dim(auc_diff)[1]
head(auc_diff)
apply(auc_diff,2,function(x) sum(x >= 0) )
auc_diff_summary
mlt_auc_diff_summary <- melt(auc_diff_summary)
mlt_auc_diff_summary <- reshape2::melt(auc_diff_summary)
mlt_auc_diff_summary
ggplot(mlt_auc_diff_summary,aes(value)) + geom_line()
df <- cbind(colnames(auc_diff), auc_diff_summary)
df <- cbind(colnames(auc_diff), auc_diff_summary)
df
colnames(df) <- c("Number of Methods", "AUC Percentage")
colnames(df) <- c("Number of Methods", "Percentage")
ggplot(df,aes(value)) + geom_line()
df
df <- cbind(1:8, auc_diff_summary)
colnames(df) <- c("Number of Methods", "Percentage")
colnames(df) <- c("Num_Methods", "Percentage")
ggplot(df,aes(Num_Methods,Percentage )) + geom_line()
df
is.data.frame(df)
df <- as.data.frame(cbind(1:8, auc_diff_summary))
colnames(df) <- c("Num_Methods", "Percentage")
ggplot(df,aes(Num_Methods,Percentage )) + geom_line()
ggplot(df,aes(Num_Methods,Percentage )) + geom_line() + theme_bw()
devtools::load_all()
set.seed(2)
x1 <- rnorm(100,  sd=20)
x21 <- rnorm(50, mean=2)
x22 <- rnorm(50, mean=-2)
x2 <- c(x21, x22)
X <- cbind(x1, x2)
labs <- c(rep(0,99),1)
xvals <- c(45,46,47,48,49,50,51)
roc_obj1 <- rep(0,7)
roc_obj2 <- rep(0,7)
for(i in 1:7){
X[100,] <-c(xvals[i],2)
Xu1 <- apply(X, 2, unitize_1)
knndistXu1 <- knn.dist(Xu1, 5)
ordX1 <- order(knndistXu1[,1], decreasing=TRUE)
roc_obj <- roc(labs, knndistXu1[,1])
roc_obj1[i] <- auc(roc_obj)
Xu3 <- apply(X, 2, unitize_3)
knndistXu3 <- knn.dist(Xu3, 5)
ordX3 <- order(knndistXu3[,1], decreasing=TRUE)
roc_obj <- roc(labs, knndistXu3[,1])
roc_obj2[i] <- auc(roc_obj)
}
plot(X, pch=20, col=c("black", "red")[as.factor(labs)])
roc_obj1
roc_obj2
library("FNN")
library("FNN")
library("pROC")
set.seed(2)
x1 <- rnorm(100,  sd=20)
x21 <- rnorm(50, mean=2)
x22 <- rnorm(50, mean=-2)
x2 <- c(x21, x22)
X <- cbind(x1, x2)
labs <- c(rep(0,99),1)
xvals <- c(45,46,47,48,49,50,51)
roc_obj1 <- rep(0,7)
roc_obj2 <- rep(0,7)
for(i in 1:7){
X[100,] <-c(xvals[i],2)
Xu1 <- apply(X, 2, unitize_1)
knndistXu1 <- knn.dist(Xu1, 5)
ordX1 <- order(knndistXu1[,1], decreasing=TRUE)
roc_obj <- roc(labs, knndistXu1[,1])
roc_obj1[i] <- auc(roc_obj)
Xu3 <- apply(X, 2, unitize_3)
knndistXu3 <- knn.dist(Xu3, 5)
ordX3 <- order(knndistXu3[,1], decreasing=TRUE)
roc_obj <- roc(labs, knndistXu3[,1])
roc_obj2[i] <- auc(roc_obj)
}
plot(X, pch=20, col=c("black", "red")[as.factor(labs)])
roc_obj1
roc_obj2
xvals <- c(4.2,4.3,4.4,4.5,4.6,4.7,4.8)
roc_obj1 <- rep(0,7)
roc_obj2 <- rep(0,7)
for(i in 1:7){
X[100,] <-c(0, xvals[i])
Xu1 <- apply(X, 2, unitize_1)
knndistXu1 <- knn.dist(Xu1, 5)
ordX1 <- order(knndistXu1[,1], decreasing=TRUE)
plot(Xu1, asp=1)
points(Xu1[100, 1],Xu1[100, 2], col="red")
roc_obj <- roc(labs, knndistXu1[,1])
roc_obj1[i] <- auc(roc_obj)
Xu3 <- apply(X, 2, unitize_3)
knndistXu3 <- knn.dist(Xu3, 5)
ordX3 <- order(knndistXu3[,1], decreasing=TRUE)
plot(Xu3[,1:2], asp=1)
points(Xu3[100, 1],Xu3[100, 2], col="red")
roc_obj <- roc(labs, knndistXu3[,1])
roc_obj2[i] <- auc(roc_obj)
}
plot(X, pch=20, col=c("black", "red")[as.factor(labs)])
roc_obj1
roc_obj2
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
outroc$nemenyi
outroc$nemenyi$means
outroc$nemenyi$intervals
devtools::load_all()
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
devtools::load_all()
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
devtools::load_all()
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
devtools::load_all()
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
devtools::load_all()
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
debut(SensitivityToNorm)
debug(SensitivityToNorm)
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
friedman_test
head(df3)
nemenyi
nemenyi$means
colnames(nemenyi$means)
is.data.frame(nemenyi$means)
names(nemenyi$means)
df4 <- df3[ ,-1]
df5 <- df4[ ,order_methods]
order_methods
order_methods <- names(nemenyi$means)
order_methods <- names(nemenyi$means)
df4 <- df3[ ,-1]
df5 <- df4[ ,order_methods]
head(df5)
nemenyi <- tsutils::nemenyi(as.matrix(df5), conf.level=0.95, sort=TRUE,  plottype="matrix", main="Nemenyi test average ranks")
devtools::load_all()
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(1)
# ----------------------------------------------------------------------
# Hypothesis Testing Section
# ----------------------------------------------------------------------
# ---- Mixed model visreg graph ----
vismod <- SensitivityToNormMixedMod(rocpr=2)
# ----------------------------------------------------------------------
# sensitivity to normalization methods
# ----------------------------------------------------------------------
# ---- Nemenyi test average ranks figure ----
outroc <- SensitivityToNorm(2)
citation(pkg="randomForest")
citation("randomForest")
citation("infothoe")
citation("infotheo")
citation("moments")
citation("ks")
citation("e1071")
citation("ggplot2")
citation("quantmod")
citation("dbscan")
citation("FNN")
citation("cluster")
citation("PMCMR")
citation("lme4")
citation("reshape")
citation("multicomp")
citation("multcomp")
citation("tsutils")
citeation("latex2exp")
citation("latex2exp")
citation("pROC")
citation(reshape2)
citation("reshape2")
citation("reshape")
library(outselect)
data(Arrhythmia_withoutdupl_05_v05)
dat <- Arrhythmia_withoutdupl_05_v05
feat <- ComputeMetaFeaturesAll(dat)
fit <- TrainModels(d=2,1,1)
library(outselect)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
data(Arrhythmia_withoutdupl_05_v05)
dat <- Arrhythmia_withoutdupl_05_v05
feat <- ComputeMetaFeaturesAll(dat)
fit <- TrainModels(d=2,1,1)
out <- PredictPerformance(feat, fit)
out
proj_mat <- matrix( c(-0.0029, 0.3323, 0.0268, 0.5432, -0.2905, 0.4280, -0.6322, -0.2245, -0.5697,  -0.0629, -0.1398, 0.3892, -0.1748, 0.1822 ), nrow=2 )
proj_mat
devtools::load_all()
data(Arrhythmia_withoutdupl_05_v05)
dat <- Arrhythmia_withoutdupl_05_v05
feat <- ComputeMetaFeaturesAll(dat)
svmout <- InstSpace(d=2)
PlotNewInstance(svmout, feat, vis=TRUE)
debug(PlotNewInstance)
PlotNewInstance(svmout, feat, vis=TRUE)
d
dim(coordinates)
algorithms
dim(x)[2]
recs
x[recs, i]
hibound[i]
x
x_bef
new_coords
print(ggplot2::ggplot(data=coordinates, ggplot2::aes(x,y))+ ggplot2::geom_point(ggplot2::aes(color=algorithms)) )
new_coords
colnames(feat)
cols <- c(149,293,239,342,160,153,273)
colnames(feat)[cols]
proj_mat <- matrix( c(-0.00292627076652680,-0.632192408787632,-0.569663704435377,-0.174829830230183,0.0268201438117375,-0.290501129270193,-0.139810891656474;0.332268685436933,-0.224517922081636,-0.0629031205759270,0.182180599272572,0.543197310499069,0.427965822151968,0.389217122011117 ), nrow=2 )
proj_mat <- matrix( c(-0.00292627076652680,-0.632192408787632,-0.569663704435377,-0.174829830230183,0.0268201438117375,-0.290501129270193,-0.139810891656474, 0.332268685436933,-0.224517922081636,-0.0629031205759270,0.182180599272572,0.543197310499069,0.427965822151968,0.389217122011117 ), nrow=2, byrow=TRUE )
proj_mat
devtools::load_all()
PlotNewInstance(svmout, feat, vis=TRUE)
devtools::load_all()
PlotNewInstance(svmout, feat, vis=TRUE)
library("FNN")
set.seed(1)
n=20
x.ori.1 <- cbind(runif(n),runif(n, min=0, max=2))
x.ori <- rbind(x.ori.1, c(0.4,5))
knn.ori <- knn.index(x.ori,1)
plot(x.ori, asp=1, main="Original")
x.1 <- apply(x.ori,2,unitize_1)
knn.1 <- knn.index(x.1,1)
plot(x.1, asp=1,  main="Min-Max")
x.2 <- apply(x.ori,2,unitize_2)
knn.2 <- knn.index(x.2,1)
plot(x.2, asp=1, main="Mean-SD")
x.3 <- apply(x.ori,2,unitize_3)
knn.3 <- knn.index(x.3,1)
plot(x.3, asp=1, main="Median-IQR")
x.4 <- apply(x.ori,2,unitize_4)
knn.4 <- knn.index(x.4,1)
plot(x.4, asp=1, main="Median-MAD")
cbind(knn.ori, knn.1, knn.2, knn.3, knn.4)
knn.mat <- cbind( knn.1, knn.2, knn.3, knn.4)
sum(apply(knn.mat,1,function(x) length(unique(x))>1))
set.seed(1)
n=20
x.ori.1 <- cbind(runif(n),runif(n, min=0, max=2))
x.ori <- rbind(x.ori.1, c(0.4,5))
knn.ori <- knn.index(x.ori,1)
plot(x.ori, asp=1, main="Original")
x.1 <- apply(x.ori,2,unitize_1)
devtools::load_all()
x.1 <- apply(x.ori,2,unitize_1)
knn.1 <- knn.index(x.1,1)
plot(x.1, asp=1,  main="Min-Max")
x.2 <- apply(x.ori,2,unitize_2)
knn.2 <- knn.index(x.2,1)
plot(x.2, asp=1, main="Mean-SD")
x.3 <- apply(x.ori,2,unitize_3)
knn.3 <- knn.index(x.3,1)
plot(x.3, asp=1, main="Median-IQR")
x.4 <- apply(x.ori,2,unitize_4)
knn.4 <- knn.index(x.4,1)
plot(x.4, asp=1, main="Median-MAD")
library("ggplot2")
set.seed(1)
n=100
nn.changes <- matrix(0,nrow=100,ncol=20)
for(d in 1:20){ # set dimension
for(k in 1:100){ # repeat each experiment 100 times
## make x.ori
for(i in 1:d){
temp <- runif(n, min=0, max=i)
if(i==1){
x.ori <- temp
out.obs <- 0.5
}else{
x.ori <- cbind.data.frame(x.ori,temp)
out.obs <- c(out.obs,(i+1))
}
}
## add outlier
x.ori <- rbind.data.frame(x.ori,out.obs)
x.1 <- apply(x.ori,2,unitize_1)
knn.1 <- knn.index(x.1,1)
x.2 <- apply(x.ori,2,unitize_2)
knn.2 <- knn.index(x.2,1)
x.3 <- apply(x.ori,2,unitize_3)
knn.3 <- knn.index(x.3,1)
x.4 <- apply(x.ori,2,unitize_4)
knn.4 <- knn.index(x.4,1)
knn.mat <- cbind( knn.1, knn.2, knn.3, knn.4)
nn.changes[k,d] <- sum(apply(knn.mat,1,function(x) length(unique(x))>1))
}
}
mean.vals <- apply(nn.changes,2,mean)/101
sd.vals <- apply(nn.changes,2,sd)/101
new.dat <- cbind.data.frame(1:20,mean.vals,sd.vals)
colnames(new.dat) <- c("Dimension", "nn_changed", "SD")
plot(mean.vals)
ggplot(new.dat, aes(x=Dimension,y=nn_changed*100 ))+ geom_point() + labs(y="Nearest Neighbour different %") +  geom_errorbar(data=new.dat,mapping=aes(x=Dimension,ymin=(nn_changed-SD), ymax=(nn_changed+SD)))
ggplot(new.dat, aes(x=Dimension,y=nn_changed ))+ geom_point() + labs(y="Nearest Neighbour different %", title="Normalization techniques affecting nearest neighbours")
plot(mean.vals)
new.dat
ggplot(new.dat, aes(x=Dimension,y=nn_changed ))+ geom_point() + labs(y="Nearest Neighbour different %", title="Normalization techniques affecting nearest neighbours")
library("outselect")
library("ggplot2")
library("reshape2")
library("visreg")
library("FNN")
library("pROC")
ddsp <- DifficultyDiversitySpace()
df <- ddsp$dfall
ggplot(df, aes(difficulty, diversity)) + geom_point(aes(color=source)) + theme(legend.position="none") + xlab("Difficulty") + ylab("Diversity")
outN <- IsNormalizingBetter()
outN$pvalues
outN$normed_better
# ---- Mixed model visreg graph ----
vismod <- SensitivityToNormMixedMod(1)
4/19
5/19
6/19
77*6
devtools::load_all()
## TABLE 8 Results
out_xi05 <- PredictNormMethod(rocpr=1, xi=0.05)
devtools::load_all()
debug(PredictNormMethod)
out_xi10 <- PredictNormMethod(rocpr=1, xi=0.10)
rm_cols
sds
which(sds==0)
c(1, which(sds==0))
rm_cols
max(apply(feat,2,max))
max(apply(feat[,-1],2,max))
sds <- apply(feat[,-1], 2, sd)
which(sds==0)
c(1, which(sds==0)+1)
devtools::load_all()
debug(PredictNormMethod)
## TABLE 8 Results
out_xi05 <- PredictNormMethod(rocpr=1, xi=0.05)
rm_cols
devtools::load_all()
## TABLE 8 Results
out_xi05 <- PredictNormMethod(rocpr=1, xi=0.05)
devtools::load_all()
devtools::load_all()
## TABLE 8 Results
out_xi05 <- PredictNormMethod(rocpr=1, xi=0.05)
citation("ks")
